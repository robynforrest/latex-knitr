%% mainDoc.Rnw - Main part of the document
%% Note the variables such as \fishname are global from the calling file (example.Rnw)

\nonumsection*{ABSTRACT}\addcontentsline{toc}{section}{ABSTRACT}

Summary of objectives, methods and results...

\newpage

\nonumsection*{R\'ESUM\'E}\addcontentsline{toc}{section}{R\'ESUM\'E}

Usually the french version of the abstract goes here, but it is included here to show how accents might be added to text and how non-numbered sections work.

\clearpage

%% Need numbering back to Arabic.
\pagenumbering{arabic}
\setcounter{page}{1}

\section{INTRODUCTION}
Hecate Strait and Queen Charlotte Sound contain some of the most productive fishing grounds in British Columbia (BC), providing key habitat for many commercially important groundfish species. This project will employ multivariate statistics and geostatistical approaches to analyse relationships between environmental factors and distribution and productivity of key groundfish populations in Hecate Strait and Queen Charlotte Sound. The project will improve advice for management of Pacific groundfish stocks by: (i) improving understanding of environmental drivers of groundfish distribution and productivity needed for ecosystem-based management; (ii) improved estimates of abundance for key species; (iii) identification of juvenile habitats;  (iv) provision of a baseline for understanding impacts of environmental change on species distribution; and (v) identification of species that could indicate ecosystem change through shifts in distribution and productivity.

Distribution and abundance of groundfish species is associated with invariant (e.g., depth, bottom-type) and variable (e.g., temperature, salinity) environmental factors [1][2][3].  Measuring relationships between these factors and distribution and abundance is the first step in understanding drivers of productivity (recruitment, growth, mortality), which is a critical component of ecosystem-based management. This project will employ statistical and hierarchical Bayesian geostatistical models ([4][5][2][3]) to analyse relationships between environmental factors and distribution, abundance and size structure of a set of key, commercially harvested groundfish species in Hecate Strait and Queen Charlotte Sound. Models will utilize data from commercial trawl logbooks and fishery independent surveys. Temperature and salinity data from the Regional Oceanographic Model System (ROMS) [6] will provide key model inputs.

Results for each species will include maps of predicted distribution and abundance of adults and juveniles; Bayesian predictive probability distributions of the relationships between habitat and environmental factors and abundance; and plots of the distribution of adults and juveniles along environmental gradients. Species most likely to be impacted by large environmental changes (e.g., ocean temperature) will be identified. Working with our external collaborator, results for a subset of species will be compared to results from Alaska to test generality of results and identify key differences. The project will provide updated estimates of abundance for the species of interest and will identify locations that may represent critical juvenile habitat. Results will be published in the primary literature, and in a CSAS Research Document reviewed through the Centre for Science Advice Pacific.

In the long-term, the project will provide important baseline data for understanding potential future impacts of environmental change. Some species (e.g., Pacific Cod) are known to vary their habitat with depth to maintain a limited temperature range [1], indicating that their distribution could be strongly affected by long-term changes in ocean temperature. Published studies have shown that large-scale redistribution of north Pacific fish populations may occur under future climate scenarios, with the potential for large impacts on ecosystem structure and function [7][8]. Groundfish indicator species most likely to be affected by environmental change will be identified in this project.  Finally, ecosystem-based fishery management is based on principles of understanding the structure and function of the living components of marine ecosystems. In the US, NOAA is mandated to identify habitats essential for every managed fish species and identify those habitats that contribute most to survival, growth and productivity [9]. The analyses in this project will form an important component of this understanding for central and northern BC waters. Through partnership with our external collaborator, comparative analyses will test generality of results and identify differences between BC and Alaska.

\bigskip

\section{METHODS}
\subsection{Groundfish Bottom Trawl Survey}
Groundfish bottom trawl survey data for our analyses were based on data collected during the DFO's Hecate Strait Synoptic Trawl Survey and the Queen Charlotte Sound Synoptic Trawl Survey between 1984 and 2015. 
Tows began at pre-determined locations as part of a stratifiedrandom sampling design with strata based on (?????). Fish were identified to species, lengths measured, sexed (0 = unknown, 1 = male, 2 = female, 3 = ?), and characterised by maturity (categories 1 to 7). A sub-sample of each fish species from every tow were grouped by species and weighed to the nearest kilogram (kg). Tow length and travel speed were also recorded. The data use this analysis are therefore the biomass of each species in each tow, and in some cases, standardised as catch per unit of trawl effort (cach per square kilometre). 

During the groundfish bottom trawl survey average net depth and ocean temperature data were collected from sensors attached to the net. These data are not available for all tows.


\subsection{Habitat Data}
Substrate type (e.g. hard, sandy, muddy) and ocean depth for the study area was obtained from the \bc Marine Conservation Analysis database.

\subsection{Cumulative Distribution Functions}
The purpose this component of the study was to identify significant associations between environmental parameters and the distributions of 20 species of northeast Pacific Ocean groundfish. It was also meant to be a continuation and an update on what was presented by \citet{psf94}. We used cumulative distribution functions (cdf) of fish catch (CPUE) and the  environmental factors described above (substrate, salinity, temperature and depth) \citep{ps94, psf94}. This technique calculates the empirical cdf's for the environmental parameters alone and the environmental parameters weighted by the CPUE of a particular species \citep{ps94, psf94}. 
The probability associated with each observation in a cdf is 1/\emph{n}. Therefore the cdf for a given habitat variable ($x_{i}$) is of the form \citep{cd86}:


\begin{align} \label{eq:cdf1}
\emph{f}(t) = \sum_{h}\sum_{i}\frac{1}{1}\emph{I}({x_{i}})
\end{align}

\begin{addmargin}[3em]{1em}
with the indicator function
\end{addmargin}

\begin{align}
\emph{I}({x_{i}}) = 1,0 if ({x_{i}}) %$\leqslant  t$; otherwise
\end{align}


Where \emph{t} represents an index, ranging from the lowest to the highest values of the habitat parameter at a step appropriate for the desired resolution. Equation 1 is calculated over all values of \emph{t} for each habitat measurement ($x_{i}$) available. 

The cdf's derived from Equation 1 can be used to determine the proportion of the environmental-weighted catch within any range of the environmental variable during the survey.

Copied directly from Perry and Smith 1994. Including the survey stratification scheme via the $W_h$/$n_h$ terms ensures that we have an unbiased estimate of the frequency distribution for the habitat measurement. Ignoring the stratification by replacing $W_h$/$n_h$ with 1/\emph{n} would result in either under- or overestimating the area associated with any particular value of the habitat measurement. However, he term  $W_h$/$n_h$ does simplify to 1/\emph{n}  when the number of sets allocated to each stratum is proportional to the size of the stratum (i.e., $n_h$ = $nW_h$). That is stratification can be ignored when the allocation of sets is strictly proportional to the stratum size.
Next, we associate the catch of fish (in weight) of a particular species in each tow with the habitat parameters during that tow as  weight in the form:

\begin{align} \label{eq:cdf2}
g(t) = \sum_{h}\sum_{i}\frac{1}{1}\emph{I}({x_{i}})
\end{align}


\subsection{Models}
The project will apply a mix of established and recently-published statistical approaches to achieve the deliverables of the project. An earlier study [1] applied a set of multivariate statistical models to classify groundfish species in Hecate Strait according to their relationships with invariant and variable environmental factors. Recent studies have further developed these types of approaches for Alaskan groundfish species (e.g., [2][3]). A problem with spatial datasets for many marine species is the high proportion of zero observations, which can bias results. One approach to solving this problem is to use a two-stage model to first predict presence and absence, then analyse relationships between environmental variables and abundance [10]. More recently, the problem has been addressed using new Bayesian hierarchical models which estimates both the probability of zero observations and abundance in a hierarchical framework [4][5]. Within this framework, a geostatistical approximation, consisting of a linear model with spatially-correlated errors, is used to efficiently predict spatial abundance as a function of environmental factors [5]. The model outputs spatial predictions of abundance, and predictive probability distributions of the effects of each environmental factor on abundance for each species. 
Models are calibrated with spatial abundance observations. Analyses can be done on different size-classes of the population to better understand differences in adult and juvenile distribution and improve understanding of productivity. 

\subsection{Data}
The project utilised spatial data from DFO's Groundfish Synoptic Bottom Trawl Surveys in Hecate Strait and Queen Charlotte Sound. These biennial surveys have been operating since 2003 and employ a random, stratified sampling design. Spatially-resolved catch weight of more than 100 species is recorded from each tow. Length, weight, sex, maturity and age data were collected, according to a prioritized sampling protocol. Temperature, dissolved oxygen and salinity and depth data were also recorded. Highly spatially-resolved, commercial logbook data were available from BC's 100\%-observed groundfish bottom trawl fishery. All these data are held in Oracle databases, co-managed by the Pacific Groundfish Statistics Program. Spatially-gridded predictions of temperature and salinity data for Hecate Strait and Queen Charlotte Sound, were output from the Regional Oceanographic Model System at the Institute of Ocean Sciences. Spatial bottom-type data at 100 m and 20 m resolution were available at the Pacific Biological Station. Scientists at NOAA's Alaska Fisheries Science Center are currently engaged in developing distribution maps for all commercially-fished species in Alaska. Some of these data were available, via our external collaborator Dr. Rooper.
Software: A version of the hierarchical Bayesian model has already been written using the OpenBUGS programming language. This code was customized and refined for this project. All other statistical models and graphic outputs were developed using the R-programming language. Species abundance and data distribution maps were made using ArcGIS or a similar (e.g., QGIS, PBSMapping).

\subsection{Data Management}
Spatially-gridded Canadian datasets and gridded predictions of distribution and abundance were transferred to a database managed by the Pacific Groundfish Statistics program.  They were available internally to Pacific stock assessment scientists, and by request externally. Maps were incorporated into an intranet-based tool, making them available to Pacific scientists and managers. 

%%Open the file \rnwexamplefile. Look at the first R code chunk, starting on line 191. This is where the R environment is loaded so that the figures and tables can be made, and values can be referenced later in the document. There are two choices: source the R file, or load a binary R environment. Sourcing the file works fine, but if there is a lot of loading of data or calculations that have to happen during the sourcing the build will take a long time. A much quicker way is to open an R session, and source the \rfile\ manually, then save the R environment to a file called \rdata\ in the \emph{r} directory. If this method is used, make sure to set \textbf{\lstinline{use.binary.envir <- TRUE}} on line 209 of \rnwexamplefile.

%To build this document, open a command line and enter \textbf{buildtex.bat}. When you run buildtex.bat two things happen:
%\begin{enumerate}[noitemsep,nolistsep]
%  \item Rscript calls knitr which goes through and \emph{knits} your \emph{\rnwexamplefile} file, which means it runs all the R code it finds, stores figures in the \emph{knitr-cache} directory, and creates a \tex file which \latex can then understand. It also creates a file called knitrOutput.log which contains all output and errors encountered during the knitting procedure. That is where to first look when there are problems compiling your document. Here is the line in buildtex.bat that does this:
 %% alltt allows us to enter code with a bunch of special characters without having to escape all of them explicitly.
%    \begin{alltt}
%      Rscript -e "library(knitr);knit('./\rnwexamplefile')" 1> knitrOutput.log 2>&1
%    \end{alltt}
%  \item \latex runs through the newly-created \tex file (\emph{\texfile}) and calls \emph{bibtex} to find the references and make the bibliography. There are three output formats of the document: .ps, .dvi, and .pdf. The .ps and .dvi formats require special viewers (Yap and GhostView respectively) and do not incorporate the reference links that are so convinient in the .pdf file. During development of very complex documents, you can leave the last part of this call out to avoid PDF generation, and put it back in when ready to complete the document.
%    \begin{alltt}
%      @latex -synctex=1 "\texfile" && bibtex "example" && latex "\texfile"
%        && latex "\texfile" && dvips "example.dvi" && ps2pdf "example.ps"
%    \end{alltt}
%\end{enumerate}

%Some \latex packages may have to be installed. If so, the package manager dialog will open. You must choose to install from internet, then make sure to select \emph{ctan} using \emph{HTTP} protocol from \emph{BC}. The default settings will most likely not work.

\subsection{More Results}

%When \emph{knitr} is called, it parses the \emph{\rnwexamplefile} file, looking for special parenthesis characters which are called \emph{R code chunks}. The chunks begin with a set of parentheses and equals sign \verb!<< >>=! and end with the \emph{at} symbol \verb!@!. Anything between them is an R code chunk which will be evaluated by \emph{knitr}. Inside the beginning parentheses, you can define many \emph{chunk options}. The official page listing these options is here: \href{http://yihui.name/knitr/options/}{Knitr chunk options}. In this document the file \emph{\rnwexamplefile} holds one chunk which loads the R environment, and \emph{\rnwmaindocfile} holds the figure chunks (one for each figure) which each hold simple commands to plot some examples. For example, figure \ref{fig:example-half-torus} is called like this:

%% Outputs the chunk as code into the document by using eval=FALSE and literal=TRUE
%\verb!<<fig.height=9, fig.width=8>>=! \\
%\verb!half.torus()! \\
%\verb!@!

\subsubsection{Even more results}
%One should always write calculated values or data by using a reference to the R objects instead of typing the numbers in as text. This way, if something changes you don't have to read and verify every number in your document, they will be updated automatically by \emph{knitr}.

%Here's how you write some values by reference from your R environment inside \latex text block: For example to get the mean of x you would use the command: \$\ShowSexpr{mean(x)}\$ which in this case evaluates to $\Sexpr{mean(x)}$. The \verb!$\Sexpr{}$! construct represents an S-expression, where S was the predecessor to R. For some reason it hasn't yet been changed to \verb!$\Rexpr{}$!. In this example, the values for the x vector were read in from \emph{example.r} at the beginning of the knitting process and is accessible throughout the document. You can call simple R commands using the \verb!$\Sexpr{}$! command inside \latex. You can do more than one command by separating with a semicolon, for example the command \$\ShowSexpr{z=x+y;mean(z)}\$ evaluates to $\Sexpr{z=x+y;mean(z)}$ for the x and y values loaded from \emph{example.r}.\\

\subsection{Even  more and more results}

%If there's an error, the first thing to do is check the \emph{knitrOutput.log} file. This will contain all messages both regular and error which \emph{knitr} outputs. If there was an error during the knitting process, you will find it there. The last lines of the file should say:
%\begin{alltt}
%  output file: \texfile

%  [1] "\texfile"
%\end{alltt}
%If you see this message and the file \emph{\texfile} exists then the \emph{knitr} part has worked but the \latex part of the compilation has failed. The message in the case that \latex has failed will be something like \emph{l.132...error message}. In that case, the error happened on line 132 of the \emph{\texfile} file. You will have to look at this file first to see where the error is, then go back to your \rnwexamplefile\ file and fix it. Sometimes errors earlier on can trigger something later to fail, which makes it very hard to debug. The best advice is to compile after every change to make sure it is still working. A lot of time can be wasted tracking down errors if you haven't compiled in a long time and made many changes, where more than one error may have been introduced. Matching parenthesis errors can be particular insidious.

%If there is an error stating:

%\emph{**** Could not open the file example.pdf}

%it means that you still have the PDF open and you need to close it and re-compile. If you have the GhostView viewer, you can keep the postscript (\emph{example.ps}) file open instead while developing. You won't get an error even if it stays open.

\bigskip

\section{RESULTS}
%Equations are fairly straightforward, and if organized using the same label prefix (\textbf{eq:}), they will be numbered automatically. Here are some example equations from the 2015 \fishnameARF\ assessment with added margins for captions:

%\begin{align} \label{eq:length-temp-lm}

%B_y = \sum_{i=1}^kC_{y_i}A_i=\sum_{i=1}^kB_{y_i}
%\end{align}

%\begin{addmargin}[3em]{1em}
%where $\overline{L}$ is the mean \fishnameARF\ length...
%\end{addmargin}

%\begin{align} \label{eq:length-temp-lm}
%\overline{L}_s = B_{0} + \overline{T}_{D_s} + Y_s + \overline{D}_{s} + \overline{T}_{D_s} * \overline{D}_{s} * Y_s
%B_y = \sum_{i=1}^kC_{y_i}A_i=\sum_{i=1}^kB_{y_i}
%\end{align}

%\begin{addmargin}[3em]{1em}
%where $\overline{L}$ is the mean \fishnameARF\ length...
%\end{addmargin}


%CPUE ($C_{y_i}$) for \fishnameARF\ in stratum $i$ for year $y$ was calculated as a density in $kg/km^2$ by:

%%\begin{align} \label{eq:cpuecalc}
%C_{y_i}=\frac{\sum\limits_{j=1}^{n_{y_i}} \left[\frac{W_{y_i,j}}{D_{y_i,j}w_{y_i,j}}\right]}{n_{y_i}}
%\end{align}
%\begin{addmargin}[3em]{1em}
%where $W_{y_i,j}$ is the catch weight in $kg$ for \fishnameARF\ in stratum $i$, year $y$, and tow $j$, $D_{y_i,j}$ is the distance travelled in $km$ for tow $j$ in stratum $i$ and year $y$, $w_{y_i,j}$ is the net opening in $km$ by tow $j$, stratum $i$, and year $y$, and $n_{y_i}$ is the number of tows in stratum $i$.
%\end{addmargin}

%The variance of the survey biomass estimate $V_y$ for \fishnameARF\ in year $y$ is calculated in $kg^2$ as follows:
%\begin{align} \label{eq:indexvariance}
%V_y=\sum_{i=1}^k\left[\frac{\sigma_{y_i}^2A_i^2}{n_{y_i}}\right]=\sum_{i=1}^kV_{y_i}
%\end{align}
%\begin{addmargin}[3em]{1em}
%where $\sigma_{y_i}^2$ is the variance of the CPUE in $kg^2/km^4$ for year $y$ in stratum $i$, $V_{y_i}$ is the variance of \fishnameARF\ in stratum $i$ for year $y$, where $\sigma_{y_i}^2$ was obtained from bootstrapped samples (see below).
%\end{addmargin}

%The CV for \fishnameARF\ for each year $y$ was calculated as follows:
%\begin{align} \label{eq:indexcv}
%CV_y=\frac{\sqrt{V_y}}{B_y}
%\end{align}
%\begin{addmargin}[3em]{1em}
%where $CV_y$ is the CV for year $y$.
%\end{addmargin}

%\subsubsection{A few more equation tidbits}

%Here is an example of overline usage: $\overline{R}_{init}$.

%Double dashes can be used to make a longer solid line to show value ranges: $0.308 y^{-1}$--$0.406 y^{-1}$.

%Here's how you show a fraction inline: $\frac{B_{2016}}{B_{ReferencePoint}} < 1$.

\bigskip

\section{ENVIRONMENTAL COVARIATES} \label{sec:enviro.covar}

Environmental covariates considered during this study included ocean depth, and bottom temperature and depth. Temperature and salinity data were collected during the groundfish trawl surveys and were available from the Regional Oceanographic Model System (ROMS). 

\newpage
\graphicspath{ {c:/GitHub/SPERA-Maps/Results/Figures/} }
\begin{figure*}
        \centering
        \begin{subfigure}[b]{0.475\textwidth}
            \centering
            \includegraphics[width=\textwidth]{Depth3km_gridded.eps}
            \caption[]
            {{\small Mean ocean depth (m) in grid cells of 3 km x 3 km for fishing events from all groundfish trawl surveys for all years.  }}    
            \label{fig:allsurveysdepth}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.475\textwidth}  
            \centering 
            \includegraphics[width=\textwidth]{SurveyTemp3km_gridded.eps}
            \caption[]%
            {{\small Mean bottom temperature ($^\circ$C) in grid cells of 3 km x 3 km for fishing events from all groundfish trawl surveys for all years.}}    
           \label{fig:allsurveystemp}
        \end{subfigure}

        \caption[ ]
        {\small Summary of environmental covariate data. See Table XX for a list of surveys.} 
        \label{fig:covariatefigures}
    \end{figure*}

\newpage
\clearpage

\graphicspath{ {c:/GitHub/SPERA-Maps/Results/Figures/} }
\begin{figure*}
        \centering
        \begin{subfigure}[b]{0.475\textwidth}
            \centering
            \includegraphics[width=\textwidth]{ROMSTemp3km_gridded.eps}
            \caption[]
            {{\small Ocean floor temperature ($^\circ$C) from ROMS in grid cells of 3 km x 3 km for XX years.}}    
            \label{fig:ROMStemp}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.475\textwidth}  
            \centering 
            \includegraphics[width=\textwidth]{ROMSSalinity3km_gridded.eps}
            \caption[]%
            {{\small Mean bottom salinity (PSU) from ROMS in grid cells of 3 km x 3 km for XX years.}}    
           \label{fig:ROMSsalinity}
        \end{subfigure}
        \caption[ ]
        {\small Regional Oceanographic Model System (ROMS) ocean floor temperature ($^\circ$C) and salinity (PSU) data from XX years.} 
        \label{fig:ROMSfigures}
    \end{figure*}

\newpage


\section{HOW REFERENCES WORK} \label{sec:how.refs.work}

\subsection{How the figure and table references work} \label{subsec:how.figure.refs.work}

See Figures \ref{fig:example-random-stuff}, \ref{fig:example-brownian-motion}, \ref{fig:example-half-torus}, and \ref{fig:example-galaxy}. Note that these numbers are clickable and you can go directly to the figure. These are referenced figures.

A figure/table reference works by adding a reference name to a figure/table, then remembering what is was and using a \verb!\ref! command to reference the figure/table. For example in Figure \ref{fig:example-random-stuff}, the figure reference code has a label tag like this \verb!\label{fig:example-random-stuff}!. The figure can be referenced anywhere in the latex document by using this syntax: \verb!\ref{fig:example-random-stuff}!. The numbering is taken care of for you and is separate for each type of reference. Here is a list of suggested prefixes to use for different reference types:

\begin{enumerate}[noitemsep,nolistsep]
  \item    \textbf{sec}: - section
  \item \textbf{subsec}: - subsection
  \item    \textbf{fig}: - figure
  \item    \textbf{tab}: - table
  \item     \textbf{eq}: - equation
  \item    \textbf{lst}: - code listing
  \item    \textbf{itm}: - enumerated list item (like this list)
  \item   \textbf{chap}: - appendix
\end{enumerate}

\subsection{How appendix references work} \label{subsec:how.appendix.refs.work}

Appendix references are much like chapters of a book. They can be added or commented out easily at the bottom of \emph{\rnwexamplefile}. This helps with the incremental form of development where you make sure the main document is compiling and then when ready, uncomment the appendix inclusion code and the appendix will be included in the document. Once included, any appendix references will be resolved.

The code which adds an appendix is \emph{knitr} code because you want the appendix added before the knitting process so that any figures or R expressions are resolved, just like in the main document. This is an example of how appendix code is added:

\verb!\rfoot{Appendix A -- Species Summaries}!

\verb!<<appendix-A, child='appendix-A/appendix-A.Rnw'>>=! \\
\verb!@!

 To reference this appendix, use this syntax: \verb!\ref{chap:example.1}! which resolves to appendix \ref{chap:example.1}. This is also clickable and will take you directly to the appendix. The reference must be defined at the beginning of \emph{\rnwappendixAfile} like this: \verb!\label{chap:example.1}!. This method is repeated for all appendices. They will be lettered in the order in which they appear in \rnwexamplefile, so it is very easy to change the order of appendices and rebuild the document.
 
\bigskip


\section{SUMMARY}

Here's a reference to an appendix: % \ref{chap:propfemale} and \ref{chap:agecompweight}.\\

\addcontentsline{toc}{section}{BIBLIOGRAPHY}

\bibliographystyle{resDoc}
%% This tells latex that the bibliography file is two directories up and is called all.bib
\bibliography{../../all}

\clearpage

\section{TABLES}

%% \begin{table}[!htp]
%% \centering
%% \caption{\label{tab:surveySuitability} Attributes of fishery-independent surveys and evaluation of suitability for stock indexing. RS=Random stratified design, BT=Bottom trawl gear.}
%% \begin{tabular}{lcccc}
%% \hline
%% \textbf{Attribute}              & \textbf{WCVISS} & \textbf{HSSS} & \textbf{HSMSAS} & \textbf{QCSSS} \\
%% \hline
%% \textbf{Design}                   &            RS &            RS &             RS &            RS \\
%% \textbf{Gear}                     &            BT &            BT &             BT &            BT \\
%% \textbf{Year Range (years)}       & 2004-2014 (6) & 2005-2013 (5) & 1984-2003 (11) & 2003-2013 (7) \\
%% \textbf{Set Range (avg)}          & 106-179 (153) & 156-236 (189) &   88-161 (105) & 260-281 (269) \\
%% \textbf{PFMA Areas}               &         3C,3D &         5C,5D &          5C,5D &         5A,5B \\
%% \textbf{Depth Range (m)}          &        41-660 &        19-420 &         18-232 &        41-626 \\
%% \textbf{Ageing done (yrs)}        &       Yes (5) &       Yes (5) &        Yes (1) &       Yes (4) \\
%% \textbf{Comment}                  &               &               &                &               \\
%% \hline
%% \end{tabular}
%% \end{table}

%% The big [H] below tells latex to keep the table/figure here in this spot when using the float package
%% If it wasn't there, figures and tables would be mixed together due to latex's auto-placement algorithms
\begin{table}[H]
\centering
\caption{\label{tab:parampriors}Estimated and fixed parameters and prior probablilty distributions used in the Reference Case.}
\begin{tabular}{lcrr}
\hline
\textbf{Parameter} & \specialcell{\textbf{Number}\\\textbf{estimated}} & \specialcell{\textbf{Bounds}\\\textbf{[low,high]}} & \specialcell{\textbf{Prior (Mean, SD)}\\\textbf{(single value=fixed)}} \\
\hline
Log recruitment ($\ln(R_0)$)                                &  1 & [-2,6]  & Uniform \\
Steepness ($h$)                                            &  1 & [0.2,1] & Beta($\alpha=13.4$,$\beta=2.40$) \\
Log natural mortality ($\ln(M)$)                           &  1 & [-5,0]  & Normal($\ln(0.2)$,$0.2$) \\
Log mean recruitment ($\ln(\overline{R})$)                  &  1 & [-2,6]  & Uniform \\
Log initial recruitment ($\ln(\overline{R}_{init})$)         &  1  & [-2,6] & Uniform \\
Variance ratio ($\rho$)                                     &  0 & Fixed   & $0.059$ \\
Inverse total variance ($\vartheta^2$)                     &  0 & Fixed   & $1.471$ \\
Survey age at 50\% selectivity ($\hat{a}_k$)               &  3 & [0,1]   & None \\
Fishery age at 50\% selectivity ($\hat{a}_k$)               &  1 & [0,1]   & None \\
Survey SD of logistic selectivity ($\hat{\gamma}_k$)        &  3 & [0,Inf) & None \\
Fishery SD of logistic selectivity ($\hat{\gamma}_k$)       &  1 & [0,Inf) & None \\
Survey catchability ($q_k$)                                 &  4 & None    & Normal($0.5$,$1.0$) \\
Log fishing mortality values ($\Gamma_{k,t}$)                & 19 & [-30,3] & [-30,3] \\
Log recruitment deviations ($\omega_t$)                     & 19 & None    & Normal($0$,$\tau$) \\
Initial log recruitment deviations ($\omega_{init,t}$)        & 19 & None    & Normal($0$,$\tau$) \\
\hline
\end{tabular}
\end{table}

%% How you call an xtable from latex. Note there is no need for anything other than
%% the R call to make.xtable. The label can be referenced elsewhere in the document.
<<results='asis', echo=FALSE>>=
make.xtable(seed=c(1,2,3,4), xcaption=paste0("Example using xtable with some pseudo-random seeded numbers. The function ",
            "get.align makes the left column justified left and the rest justified right which ",
            "is how most tables giving values are shown."), xlabel="tab:example-xtable")
@


%\textbf{Parameter} & \specialcell{\textbf{Number}\\\textbf{estimated}} & \specialcell{\textbf{Bounds}\\\textbf{[low,high]}} & \specialcell{\textbf{Prior (Mean, SD)}\\\textbf{(single value=fixed)}} \\
\newpage

\begin{table}[H]
\centering
\caption{\label{tab:annmeansSD}\fishnameARF\ mean lengths (mm), maturity, sex and total sample weight (kg) ${\pm}$ standard deviation (SD) from 1984 to 2015.}
\begin{tabular}{lrrrrrrrr}%%lrr puts first column left-justified and the next two columns right-justified
\hline
\textbf{Survey Year} & \textbf{$\overline{L}$} & \textbf{SD} & \textbf{$\overline{S}$} & \textbf{SD} & \textbf{$\overline{M}$} & \textbf{SD} & \textbf{$\overline{TotWt}_s$} & \textbf{SD}\\ 
\hline
1984           & a                               & See Table \ref{tab:annmeansSD} \\
1987             & a                      & $\vartheta^2=1.538$; $\rho=0.015$ \\
1989             & a                       & $\vartheta^2$ estimated; $\rho=0.059$ \\
1991             & a                        & $\vartheta^2=0.962$; $\rho=0.038$ \\
1993             & a                       & $\vartheta^2=2.500$; $\rho=0.100$ \\
1998             & a            & $h$ = Beta($\alpha=12.7$, $\beta=5.0$) \\
2000             & a          & $\ln(M)$ = Normal($\ln(0.2)$, $0.05$) \\
2002             & a          & $\ln(M)$ = Normal($\ln(0.2)$, $0.25$) \\
2003           & a        & $\ln(M)$ = Normal($\ln(0.3)$, $0.20$) \\
2004          & a         & $\ln(q_k)$ = Normal($\ln(1.0)$, $1.0$) \\
2005          & a         & $\ln(q_k)$ = Normal($\ln(0.5)$, $1.5$) \\
2007          & a            & $\hat{a}$ = $4.99$ yrs; $\hat{\gamma}$ = $1.27$ yrs \\
2009          & a              & $\hat{a}$ = $6.00$ yrs; $\hat{\gamma}$ = $1.00$ yrs \\
2011         & Aa              & $\hat{a}$ = $6.00$ yrs; $\hat{\gamma}$ = $1.00$ yrs \\
2013          & a              & $\hat{a}$ = $6.00$ yrs; $\hat{\gamma}$ = $1.00$ yrs \\
2015         & a              & $\hat{a}$ = $6.00$ yrs; $\hat{\gamma}$ = $1.00$ yrs \\
\hline
\end{tabular}
\end{table}


%\begin{table}[H]
%\centering
%\caption{\label{tab:meansSD}Fish species overall mean lengths (mm), maturity, sex and total sample weight (kg) ${\pm}$ standard deviation %(SD) for all surveys (1984 to 2015).}
%\begin{tabular}{lrrrrrrrr}%%lrr puts first column left-justified and the next two columns right-justified
%\hline
%\textbf{Fish Species} & \textbf{$\overline{L}$} & \textbf{SD} & \textbf{$\overline{S}$} & \textbf{SD} & \textbf{$\overline{M}$} & \textbf{SD} & \textbf{$\overline{TotWt}_s$} & \textbf{SD} \\ 
%\hline
%\fishnameARF\           & a                               & See Table \ref{tab:meansSD} \\
%\fishnameCAR\             & a                      & $\vartheta^2=1.538$; $\rho=0.015$ \\
%\fishnameDOG\             & a                       & $\vartheta^2$ estimated; $\rho=0.059$ \\
%\fishnameDOL\             & a                        & $\vartheta^2=0.962$; $\rho=0.038$ \\
%\fishnameENL\             & a                       & $\vartheta^2=2.500$; $\rho=0.100$ \\
%\fishnameGSR\             & a            & $h$ = Beta($\alpha=12.7$, $\beta=5.0$) \\
%\fishnameLST\             & a          & $\ln(M)$ = Normal($\ln(0.2)$, $0.05$) \\
%\fishnamePAC\             & a          & $\ln(M)$ = Normal($\ln(0.2)$, $0.25$) \\
%\fishnamePEL\           & a  & $\ln(M)$ = Normal($\ln(0.3)$, $0.20$) \\
%\fishnamePOP\          & a & $\ln(q_k)$ = Normal($\ln(1.0)$, $1.0$) \\
%\fishnameRAT\          & a         & $\ln(q_k)$ = Normal($\ln(0.5)$, $1.5$) \\
%\fishnameROL\          & a            & $\hat{a}$ = $4.99$ yrs; $\hat{\gamma}$ = $1.27$ yrs \\
%\fishnameRSR\          & a              & $\hat{a}$ = $6.00$ yrs; $\hat{\gamma}$ = $1.00$ yrs \\
%\fishnameRXL\          & Aa              & $\hat{a}$ = $6.00$ yrs; $\hat{\gamma}$ = $1.00$ yrs \\
%\fishnameSGR\          & a              & $\hat{a}$ = $6.00$ yrs; $\hat{\gamma}$ = $1.00$ yrs \\
%\fishnameSST\          & a              & $\hat{a}$ = $6.00$ yrs; $\hat{\gamma}$ = $1.00$ yrs \\
%\fishnameWWR\          & Aa              & $\hat{a}$ = $6.00$ yrs; $\hat{\gamma}$ = $1.00$ yrs \\
%\fishnameYMR\          & a              & $\hat{a}$ = $6.00$ yrs; $\hat{\gamma}$ = $1.00$ yrs \\
%\hline
%\end{tabular}
%\end{table}

\begin{table}[H]
\centering
\caption{\label{tab:sensitivities-q}Sensitivity cases for $q_k$; posterior quantiles.}
\begin{tabular}{lcccccc}
\hline
\textbf{Index}  & \multicolumn{3}{c}{\textbf{Sensitivity 10}} & \multicolumn{3}{c}{\textbf{Sensitivity 11}} \\
\hline
 $\mathbf{q_k}$ & \textbf{2.5\%} & \textbf{50\%} & \textbf{97.5\%} & \textbf{2.5\%} & \textbf{50\%} & \textbf{97.5\%} \\
\hline
QCSSS  & 0.081 & 0.158 & 0.508 & 0.029 & 0.083 & 0.226 \\
HSMAS  & 0.079 & 0.121 & 0.155 & 0.035 & 0.081 & 0.136 \\
HSSS   & 0.070 & 0.118 & 0.200 & 0.027 & 0.067 & 0.136 \\
WCVISS & 0.061 & 0.104 & 0.172 & 0.022 & 0.059 & 0.118 \\
\hline
\end{tabular}
\end{table}

%% <<results='asis', echo=FALSE>>=
%% # Note that the first column will not be set to have any decimal digits because it is the TAC/Catch projection
%% cap <- "Decision Table for the Reference Case showing posterior probabilities that 2016 projected biomass B\\subscr{t} is below a set of candidate reference points and benchmarks (Table \\ref{tab:refpoints}), and probabilities that the 2015 projected harvest rate U\\subscr{t} is above U\\subscr{2014} or U\\subscr{MSY} for a given level of female-only catch."
%% makeTable(1, 7, ci=ci, burnthin=burnthin, digits=3, retxtable=TRUE, xcaption=cap, xlabel="tab:Decisions")
%% @
%% <<results='asis', echo=FALSE>>=
%% # Note that the first column will not be set to have any decimal digits because it is the TAC/Catch projection
%% cap <- "Decision Table for a sensitivity model (Selectivity = Maturity, Table \\ref{tab:sensitivities}) showing posterior probabilities that 2016 projected biomass B\\subscr{t} is below a set of candidate reference points and benchmarks (Table \\ref{tab:refpoints}), and probabilities that the 2015 projected harvest rate U\\subscr{t} is above U\\subscr{2014} or U\\subscr{MSY} for a given level of female-only catch."
%% makeTable(12, 7, ci=ci, burnthin=burnthin, digits=3, retxtable=TRUE, xcaption=cap, xlabel="tab:DecisionsSelMat")
%% @

\section{FIGURES}

%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
\begin{center}
<<fig.height=9, fig.width=8>>=
random.stuff()
@
\end{center}
%\vspace{0mm}
\caption{Random points example... Degrees are represented in \latex like this 0.1$^\circ$ and superscript like this km$^2$)}
\label{fig:example-random-stuff}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%
\clearpage


%%\begin{figure}[!htp]
%%\begin{center}
%%\includegraphics[width=6in,keepaspectratio=true]{maindoc/ARFMaturity.png}
%%\end{center}
%\vspace{0mm}
% To get the grid size in km^2 for the caption:
% While in the gui for the map, type mean(xtcall(PBSmap)$pdata$area) for the map you currently have loaded.
%\caption{Mean catch-per-unit-effort (CPUE, kg/h) of \fishname\ in grid cells 0.1$^\circ$ longitude by 0.075$^\circ$ latitude (roughly 57.8~km$^2$). The shaded cells give an approximation of the area where \fishname\ was encountered by fishing events from the groundfish trawl fishery from January 1, 1996 to October 7, 2014. Contours are 200 m and 1000 m isobaths. Red lines are PFMA area boundaries.} \label{fig:cpue} \end{figure}
%%\caption{Mean Maturity} \label{fig:maturity} \end{figure}
%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[H]
\begin{center}
<<fig.height=5, fig.width=8>>=
brownian.motion()
@
\end{center}
%\vspace{0mm}
\caption{Brownian motion example..}
\label{fig:example-brownian-motion}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
\begin{center}
<<fig.height=9, fig.width=8>>=
half.torus()
@
\end{center}
%\vspace{0mm}
\caption{Half torus example..}
\label{fig:example-half-torus}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
\begin{center}
<<fig.height=9, fig.width=8>>=
plot.galaxy.data()
@
\end{center}
%\vspace{0mm}
\caption{Galaxy example}
\label{fig:example-galaxy}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%
